{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 60/40 Portfolio Improvement Backtesting\n",
    "## Testing Alternative Asset Class Additions\n",
    "\n",
    "**Objective:** Test whether adding Infrastructure, Private Credit, and Real Assets improves the traditional 60/40 portfolio.\n",
    "\n",
    "**Date:** February 2026\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook Structure\n",
    "1. **Setup & Installation**\n",
    "2. **Data Download** (from yfinance)\n",
    "3. **Data Processing & Quality Checks**\n",
    "4. **Portfolio Construction**\n",
    "5. **Performance Metrics Calculation**\n",
    "6. **Visualization**\n",
    "7. **Statistical Testing**\n",
    "8. **Results & Conclusions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# Uncomment the lines below if packages are not installed\n",
    "\n",
    "# !pip install yfinance pandas numpy scipy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Download\n",
    "\n",
    "### 2.1 Define Tickers and Metadata\n",
    "\n",
    "**Data Availability Summary:**\n",
    "\n",
    "| Asset Class | ETF Proxy | Ticker | Available From | Limitation |\n",
    "|-------------|-----------|--------|----------------|------------|\n",
    "| US Equity | SPDR S&P 500 | SPY | 1993 | ✅ Good proxy |\n",
    "| US Bonds | iShares Core Agg | AGG | 2003 | ✅ Good proxy |\n",
    "| Infrastructure | iShares Global Infra | IGF | 2007 | ⚠️ Listed only (higher vol) |\n",
    "| Private Credit | iShares High Yield | HYG | 2007 | ⚠️ Fixed rate, not floating |\n",
    "| Private Credit | Invesco Senior Loan | BKLN | 2011 | ⚠️ Better proxy (floating) |\n",
    "| Real Assets | SPDR Natural Resources | GNR | 2010 | ⚠️ Listed equities, not land |\n",
    "| Timber | iShares Timber | WOOD | 2008 | ⚠️ Timber companies, not land |\n",
    "\n",
    "**❌ NOT available on yfinance:** NCREIF Farmland/Timberland, Cliffwater Direct Lending, EDHECinfra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configuration\n",
    "START_DATE = \"2000-01-01\"  # Request early, actual data starts later\n",
    "END_DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Data request period: {START_DATE} to {END_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all tickers to download\n",
    "TICKERS = {\n",
    "    # CORE PORTFOLIO ASSETS\n",
    "    'Equity': {\n",
    "        'ticker': 'SPY',\n",
    "        'name': 'SPDR S&P 500 ETF',\n",
    "        'expense_ratio': 0.0945,\n",
    "    },\n",
    "    'Bonds': {\n",
    "        'ticker': 'AGG',\n",
    "        'name': 'iShares Core US Aggregate Bond ETF',\n",
    "        'expense_ratio': 0.03,\n",
    "    },\n",
    "    \n",
    "    # ALTERNATIVE ASSETS\n",
    "    'Infrastructure': {\n",
    "        'ticker': 'IGF',\n",
    "        'name': 'iShares Global Infrastructure ETF',\n",
    "        'expense_ratio': 0.40,\n",
    "    },\n",
    "    'Credit_HY': {\n",
    "        'ticker': 'HYG',\n",
    "        'name': 'iShares High Yield Corporate Bond ETF',\n",
    "        'expense_ratio': 0.48,\n",
    "    },\n",
    "    'Credit_Loans': {\n",
    "        'ticker': 'BKLN',\n",
    "        'name': 'Invesco Senior Loan ETF',\n",
    "        'expense_ratio': 0.65,\n",
    "    },\n",
    "    'RealAssets': {\n",
    "        'ticker': 'GNR',\n",
    "        'name': 'SPDR S&P Global Natural Resources ETF',\n",
    "        'expense_ratio': 0.40,\n",
    "    },\n",
    "    'Timber': {\n",
    "        'ticker': 'WOOD',\n",
    "        'name': 'iShares Global Timber & Forestry ETF',\n",
    "        'expense_ratio': 0.40,\n",
    "    },\n",
    "    \n",
    "    # ADDITIONAL REFERENCE\n",
    "    'REITs': {\n",
    "        'ticker': 'VNQ',\n",
    "        'name': 'Vanguard Real Estate ETF',\n",
    "        'expense_ratio': 0.12,\n",
    "    },\n",
    "    'Commodities': {\n",
    "        'ticker': 'DBC',\n",
    "        'name': 'Invesco DB Commodity Index Fund',\n",
    "        'expense_ratio': 0.85,\n",
    "    },\n",
    "    'Gold': {\n",
    "        'ticker': 'GLD',\n",
    "        'name': 'SPDR Gold Shares',\n",
    "        'expense_ratio': 0.40,\n",
    "    },\n",
    "    'TBills': {\n",
    "        'ticker': 'BIL',\n",
    "        'name': 'SPDR Bloomberg 1-3 Month T-Bill ETF',\n",
    "        'expense_ratio': 0.1356,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(TICKERS)} tickers for download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Download Data from yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(tickers_dict, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Download adjusted close prices for all tickers.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Daily adjusted close prices\n",
    "    \"\"\"\n",
    "    # Extract ticker symbols\n",
    "    ticker_list = [info['ticker'] for info in tickers_dict.values()]\n",
    "    ticker_names = list(tickers_dict.keys())\n",
    "    \n",
    "    print(f\"Downloading {len(ticker_list)} tickers...\")\n",
    "    print(f\"Tickers: {ticker_list}\")\n",
    "    print()\n",
    "    \n",
    "    # Download all at once (faster)\n",
    "    data = yf.download(\n",
    "        ticker_list,\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        auto_adjust=True,  # Adjust for splits and dividends\n",
    "        progress=True\n",
    "    )\n",
    "    \n",
    "    # Extract Close prices\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        prices = data['Close']\n",
    "    else:\n",
    "        prices = data[['Close']]\n",
    "        prices.columns = ticker_list\n",
    "    \n",
    "    # Rename columns to asset class names\n",
    "    ticker_to_name = {info['ticker']: name for name, info in tickers_dict.items()}\n",
    "    prices.columns = [ticker_to_name.get(col, col) for col in prices.columns]\n",
    "    \n",
    "    return prices\n",
    "\n",
    "# Download data\n",
    "daily_prices = download_data(TICKERS, START_DATE, END_DATE)\n",
    "\n",
    "print(f\"\\nDownloaded data shape: {daily_prices.shape}\")\n",
    "print(f\"Date range: {daily_prices.index[0].strftime('%Y-%m-%d')} to {daily_prices.index[-1].strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "daily_prices.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Convert to Monthly Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_monthly_returns(daily_prices):\n",
    "    \"\"\"\n",
    "    Convert daily prices to monthly total returns.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Monthly returns\n",
    "    \"\"\"\n",
    "    # Resample to month-end prices\n",
    "    monthly_prices = daily_prices.resample('ME').last()\n",
    "    \n",
    "    # Calculate percentage returns\n",
    "    monthly_returns = monthly_prices.pct_change()\n",
    "    \n",
    "    # Drop first row (NaN)\n",
    "    monthly_returns = monthly_returns.dropna(how='all')\n",
    "    \n",
    "    return monthly_returns\n",
    "\n",
    "# Calculate monthly returns\n",
    "monthly_returns = calculate_monthly_returns(daily_prices)\n",
    "\n",
    "print(f\"Monthly returns shape: {monthly_returns.shape}\")\n",
    "print(f\"Date range: {monthly_returns.index[0].strftime('%Y-%m')} to {monthly_returns.index[-1].strftime('%Y-%m')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview monthly returns\n",
    "monthly_returns.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Processing & Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Availability Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality_summary(returns_df):\n",
    "    \"\"\"\n",
    "    Generate data quality summary statistics.\n",
    "    \"\"\"\n",
    "    summary = pd.DataFrame({\n",
    "        'First_Date': returns_df.apply(lambda x: x.first_valid_index()),\n",
    "        'Last_Date': returns_df.apply(lambda x: x.last_valid_index()),\n",
    "        'Total_Months': returns_df.count(),\n",
    "        'Missing': returns_df.isna().sum(),\n",
    "        'Ann_Return_%': (returns_df.mean() * 12 * 100).round(2),\n",
    "        'Ann_Vol_%': (returns_df.std() * np.sqrt(12) * 100).round(2),\n",
    "        'Min_%': (returns_df.min() * 100).round(2),\n",
    "        'Max_%': (returns_df.max() * 100).round(2),\n",
    "    })\n",
    "    \n",
    "    # Format dates\n",
    "    summary['First_Date'] = summary['First_Date'].dt.strftime('%Y-%m')\n",
    "    summary['Last_Date'] = summary['Last_Date'].dt.strftime('%Y-%m')\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Generate summary\n",
    "quality_summary = data_quality_summary(monthly_returns)\n",
    "quality_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Identify Common Analysis Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define asset groups for different analyses\n",
    "ANALYSIS_CONFIGS = {\n",
    "    'Full_Analysis': ['Equity', 'Bonds', 'Infrastructure', 'Credit_HY', 'RealAssets'],\n",
    "    'With_Floating_Credit': ['Equity', 'Bonds', 'Infrastructure', 'Credit_Loans', 'RealAssets'],\n",
    "    'Infra_Only': ['Equity', 'Bonds', 'Infrastructure'],\n",
    "    'Credit_Only': ['Equity', 'Bonds', 'Credit_HY'],\n",
    "    'Core_Only': ['Equity', 'Bonds'],\n",
    "}\n",
    "\n",
    "def find_common_period(returns_df, columns):\n",
    "    \"\"\"\n",
    "    Find the common date range where all specified columns have data.\n",
    "    \"\"\"\n",
    "    available_cols = [c for c in columns if c in returns_df.columns]\n",
    "    missing_cols = [c for c in columns if c not in returns_df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        return None, None, 0, missing_cols\n",
    "    \n",
    "    subset = returns_df[available_cols].dropna()\n",
    "    \n",
    "    if subset.empty:\n",
    "        return None, None, 0, []\n",
    "    \n",
    "    return subset.index[0], subset.index[-1], len(subset), []\n",
    "\n",
    "# Check each configuration\n",
    "print(\"Available Analysis Periods:\\n\")\n",
    "print(f\"{'Configuration':<25} {'Start':<10} {'End':<10} {'Months':<8} {'Status'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for config_name, columns in ANALYSIS_CONFIGS.items():\n",
    "    start, end, months, missing = find_common_period(monthly_returns, columns)\n",
    "    if missing:\n",
    "        print(f\"{config_name:<25} {'N/A':<10} {'N/A':<10} {0:<8} Missing: {missing}\")\n",
    "    elif start is not None:\n",
    "        print(f\"{config_name:<25} {start.strftime('%Y-%m'):<10} {end.strftime('%Y-%m'):<10} {months:<8} ✅ Ready\")\n",
    "    else:\n",
    "        print(f\"{config_name:<25} {'N/A':<10} {'N/A':<10} {0:<8} ❌ No data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create Analysis Dataset\n",
    "\n",
    "We'll use the **Full_Analysis** configuration with the common period where all assets have data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select primary assets for analysis\n",
    "PRIMARY_ASSETS = ['Equity', 'Bonds', 'Infrastructure', 'Credit_HY', 'RealAssets']\n",
    "\n",
    "# Filter to common period\n",
    "analysis_returns = monthly_returns[PRIMARY_ASSETS].dropna()\n",
    "\n",
    "print(f\"Analysis dataset:\")\n",
    "print(f\"  Assets: {list(analysis_returns.columns)}\")\n",
    "print(f\"  Period: {analysis_returns.index[0].strftime('%Y-%m')} to {analysis_returns.index[-1].strftime('%Y-%m')}\")\n",
    "print(f\"  Months: {len(analysis_returns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also get risk-free rate for Sharpe ratio calculations\n",
    "if 'TBills' in monthly_returns.columns:\n",
    "    rf_returns = monthly_returns['TBills'].reindex(analysis_returns.index)\n",
    "    # Fill missing with 0 (conservative assumption)\n",
    "    rf_returns = rf_returns.fillna(0)\n",
    "    print(f\"Risk-free rate data: {rf_returns.count()} months\")\n",
    "else:\n",
    "    # Use constant 2% annual rate if no T-bill data\n",
    "    rf_returns = pd.Series(0.02/12, index=analysis_returns.index)\n",
    "    print(\"Using constant 2% annual risk-free rate (T-bill data not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Portfolio Construction\n",
    "\n",
    "### 4.1 Define Portfolio Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio definitions\n",
    "# Order: [Equity, Bonds, Infrastructure, Credit, RealAssets]\n",
    "\n",
    "PORTFOLIOS = {\n",
    "    'A_Baseline_60_40': {\n",
    "        'weights': [0.60, 0.40, 0.00, 0.00, 0.00],\n",
    "        'description': 'Traditional 60/40 portfolio',\n",
    "        'color': 'black',\n",
    "    },\n",
    "    'B_Plus_Infra': {\n",
    "        'weights': [0.60, 0.30, 0.10, 0.00, 0.00],\n",
    "        'description': '60/30/10 with Infrastructure',\n",
    "        'color': 'blue',\n",
    "    },\n",
    "    'C_Plus_Credit': {\n",
    "        'weights': [0.60, 0.30, 0.00, 0.10, 0.00],\n",
    "        'description': '60/30/10 with Private Credit',\n",
    "        'color': 'green',\n",
    "    },\n",
    "    'D_Plus_RealAssets': {\n",
    "        'weights': [0.60, 0.30, 0.00, 0.00, 0.10],\n",
    "        'description': '60/30/10 with Real Assets',\n",
    "        'color': 'orange',\n",
    "    },\n",
    "    'E_Infra_Credit': {\n",
    "        'weights': [0.60, 0.25, 0.08, 0.07, 0.00],\n",
    "        'description': '60/25/8/7 Infrastructure + Credit',\n",
    "        'color': 'purple',\n",
    "    },\n",
    "    'F_All_Three': {\n",
    "        'weights': [0.60, 0.22, 0.06, 0.06, 0.06],\n",
    "        'description': '60/22/6/6/6 All Three Alternatives',\n",
    "        'color': 'red',\n",
    "    },\n",
    "    'G_Aggressive': {\n",
    "        'weights': [0.55, 0.20, 0.10, 0.08, 0.07],\n",
    "        'description': '55/20/10/8/7 Aggressive Alternatives',\n",
    "        'color': 'darkred',\n",
    "    },\n",
    "}\n",
    "\n",
    "# Display portfolio allocations\n",
    "print(\"Portfolio Allocations:\\n\")\n",
    "print(f\"{'Portfolio':<20} {'Equity':>8} {'Bonds':>8} {'Infra':>8} {'Credit':>8} {'Real':>8} {'Total':>8}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, config in PORTFOLIOS.items():\n",
    "    w = config['weights']\n",
    "    total = sum(w)\n",
    "    print(f\"{name:<20} {w[0]*100:>7.0f}% {w[1]*100:>7.0f}% {w[2]*100:>7.0f}% {w[3]*100:>7.0f}% {w[4]*100:>7.0f}% {total*100:>7.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Calculate Portfolio Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_portfolio_returns(returns_df, weights):\n",
    "    \"\"\"\n",
    "    Calculate portfolio returns given asset returns and weights.\n",
    "    Assumes monthly rebalancing to target weights.\n",
    "    \n",
    "    Parameters:\n",
    "        returns_df: DataFrame with asset returns\n",
    "        weights: list of weights [Equity, Bonds, Infra, Credit, RealAssets]\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: Portfolio returns\n",
    "    \"\"\"\n",
    "    weights_array = np.array(weights)\n",
    "    portfolio_returns = (returns_df * weights_array).sum(axis=1)\n",
    "    return portfolio_returns\n",
    "\n",
    "# Calculate returns for all portfolios\n",
    "portfolio_returns = pd.DataFrame()\n",
    "\n",
    "for name, config in PORTFOLIOS.items():\n",
    "    portfolio_returns[name] = calculate_portfolio_returns(analysis_returns, config['weights'])\n",
    "\n",
    "print(f\"Calculated returns for {len(PORTFOLIOS)} portfolios\")\n",
    "print(f\"Period: {portfolio_returns.index[0].strftime('%Y-%m')} to {portfolio_returns.index[-1].strftime('%Y-%m')}\")\n",
    "print(f\"Months: {len(portfolio_returns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview portfolio returns\n",
    "portfolio_returns.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Calculate Cumulative Wealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative wealth (starting with $100)\n",
    "initial_wealth = 100\n",
    "cumulative_wealth = initial_wealth * (1 + portfolio_returns).cumprod()\n",
    "\n",
    "print(\"Final Wealth (starting with $100):\\n\")\n",
    "final_wealth = cumulative_wealth.iloc[-1].sort_values(ascending=False)\n",
    "for name, value in final_wealth.items():\n",
    "    print(f\"  {name:<20}: ${value:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Performance Metrics Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Define Metric Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annualized_return(returns):\n",
    "    \"\"\"Calculate annualized return from monthly returns.\"\"\"\n",
    "    total_return = (1 + returns).prod() - 1\n",
    "    n_years = len(returns) / 12\n",
    "    return (1 + total_return) ** (1 / n_years) - 1\n",
    "\n",
    "def annualized_volatility(returns):\n",
    "    \"\"\"Calculate annualized volatility from monthly returns.\"\"\"\n",
    "    return returns.std() * np.sqrt(12)\n",
    "\n",
    "def sharpe_ratio(returns, rf_returns):\n",
    "    \"\"\"Calculate Sharpe ratio.\"\"\"\n",
    "    excess_returns = returns - rf_returns\n",
    "    if excess_returns.std() == 0:\n",
    "        return 0\n",
    "    return (excess_returns.mean() * 12) / (excess_returns.std() * np.sqrt(12))\n",
    "\n",
    "def sortino_ratio(returns, rf_returns, target=0):\n",
    "    \"\"\"Calculate Sortino ratio (penalizes only downside volatility).\"\"\"\n",
    "    excess_returns = returns - rf_returns\n",
    "    downside_returns = excess_returns[excess_returns < target]\n",
    "    if len(downside_returns) == 0 or downside_returns.std() == 0:\n",
    "        return np.nan\n",
    "    downside_std = downside_returns.std() * np.sqrt(12)\n",
    "    return (excess_returns.mean() * 12) / downside_std\n",
    "\n",
    "def max_drawdown(returns):\n",
    "    \"\"\"Calculate maximum drawdown.\"\"\"\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    rolling_max = cumulative.expanding().max()\n",
    "    drawdowns = cumulative / rolling_max - 1\n",
    "    return drawdowns.min()\n",
    "\n",
    "def calmar_ratio(returns):\n",
    "    \"\"\"Calculate Calmar ratio (return / max drawdown).\"\"\"\n",
    "    ann_ret = annualized_return(returns)\n",
    "    mdd = abs(max_drawdown(returns))\n",
    "    if mdd == 0:\n",
    "        return np.nan\n",
    "    return ann_ret / mdd\n",
    "\n",
    "def var_95(returns):\n",
    "    \"\"\"Calculate 95% Value at Risk (monthly).\"\"\"\n",
    "    return returns.quantile(0.05)\n",
    "\n",
    "def cvar_95(returns):\n",
    "    \"\"\"Calculate 95% Conditional VaR (Expected Shortfall).\"\"\"\n",
    "    var = var_95(returns)\n",
    "    return returns[returns <= var].mean()\n",
    "\n",
    "print(\"Metric functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Calculate All Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_metrics(portfolio_returns, rf_returns):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive metrics for all portfolios.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    for col in portfolio_returns.columns:\n",
    "        returns = portfolio_returns[col]\n",
    "        rf = rf_returns.reindex(returns.index).fillna(0)\n",
    "        \n",
    "        metrics[col] = {\n",
    "            'Ann_Return_%': annualized_return(returns) * 100,\n",
    "            'Ann_Volatility_%': annualized_volatility(returns) * 100,\n",
    "            'Sharpe_Ratio': sharpe_ratio(returns, rf),\n",
    "            'Sortino_Ratio': sortino_ratio(returns, rf),\n",
    "            'Max_Drawdown_%': max_drawdown(returns) * 100,\n",
    "            'Calmar_Ratio': calmar_ratio(returns),\n",
    "            'VaR_95_%': var_95(returns) * 100,\n",
    "            'CVaR_95_%': cvar_95(returns) * 100,\n",
    "            'Total_Return_%': ((1 + returns).prod() - 1) * 100,\n",
    "            'Positive_Months_%': (returns > 0).mean() * 100,\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(metrics).T\n",
    "\n",
    "# Calculate metrics\n",
    "metrics_df = calculate_all_metrics(portfolio_returns, rf_returns)\n",
    "\n",
    "# Round for display\n",
    "metrics_display = metrics_df.round(2)\n",
    "metrics_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Calculate Improvement vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate improvement vs baseline (Portfolio A)\n",
    "baseline = metrics_df.loc['A_Baseline_60_40']\n",
    "\n",
    "improvement_df = metrics_df.copy()\n",
    "improvement_df['Return_Diff'] = metrics_df['Ann_Return_%'] - baseline['Ann_Return_%']\n",
    "improvement_df['Sharpe_Diff'] = metrics_df['Sharpe_Ratio'] - baseline['Sharpe_Ratio']\n",
    "improvement_df['MaxDD_Diff'] = metrics_df['Max_Drawdown_%'] - baseline['Max_Drawdown_%']\n",
    "\n",
    "print(\"Improvement vs 60/40 Baseline:\\n\")\n",
    "print(improvement_df[['Ann_Return_%', 'Return_Diff', 'Sharpe_Ratio', 'Sharpe_Diff', 'Max_Drawdown_%', 'MaxDD_Diff']].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for underlying assets\n",
    "asset_correlation = analysis_returns.corr()\n",
    "\n",
    "print(\"Asset Class Correlation Matrix:\\n\")\n",
    "print(asset_correlation.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Cumulative Wealth Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative wealth\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "for name, config in PORTFOLIOS.items():\n",
    "    ax.plot(cumulative_wealth.index, cumulative_wealth[name], \n",
    "            label=f\"{name}: ${cumulative_wealth[name].iloc[-1]:,.0f}\",\n",
    "            color=config['color'],\n",
    "            linewidth=2 if name == 'A_Baseline_60_40' else 1.5,\n",
    "            linestyle='-' if name == 'A_Baseline_60_40' else '--')\n",
    "\n",
    "ax.set_title('Cumulative Wealth: $100 Initial Investment', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Portfolio Value ($)')\n",
    "ax.legend(loc='upper left', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add recession shading for 2008-2009 and 2020\n",
    "ax.axvspan('2008-01-01', '2009-06-30', alpha=0.1, color='red', label='GFC')\n",
    "ax.axvspan('2020-02-01', '2020-04-30', alpha=0.1, color='red', label='COVID')\n",
    "ax.axvspan('2022-01-01', '2022-12-31', alpha=0.1, color='orange', label='2022 Inflation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Drawdown Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_drawdown_series(returns):\n",
    "    \"\"\"Calculate drawdown series.\"\"\"\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    rolling_max = cumulative.expanding().max()\n",
    "    drawdowns = cumulative / rolling_max - 1\n",
    "    return drawdowns\n",
    "\n",
    "# Calculate drawdowns for all portfolios\n",
    "drawdowns = pd.DataFrame()\n",
    "for col in portfolio_returns.columns:\n",
    "    drawdowns[col] = calculate_drawdown_series(portfolio_returns[col])\n",
    "\n",
    "# Plot drawdowns\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Plot only key portfolios for clarity\n",
    "key_portfolios = ['A_Baseline_60_40', 'B_Plus_Infra', 'E_Infra_Credit', 'F_All_Three']\n",
    "\n",
    "for name in key_portfolios:\n",
    "    config = PORTFOLIOS[name]\n",
    "    ax.fill_between(drawdowns.index, drawdowns[name] * 100, 0,\n",
    "                    alpha=0.3, label=name, color=config['color'])\n",
    "    ax.plot(drawdowns.index, drawdowns[name] * 100, color=config['color'], linewidth=1)\n",
    "\n",
    "ax.set_title('Portfolio Drawdowns Over Time', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Drawdown (%)')\n",
    "ax.legend(loc='lower left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Risk-Return Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk-Return scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for name, config in PORTFOLIOS.items():\n",
    "    x = metrics_df.loc[name, 'Ann_Volatility_%']\n",
    "    y = metrics_df.loc[name, 'Ann_Return_%']\n",
    "    ax.scatter(x, y, s=150, color=config['color'], label=name, alpha=0.8)\n",
    "    ax.annotate(name.split('_')[0], (x, y), textcoords=\"offset points\", \n",
    "                xytext=(5, 5), fontsize=9)\n",
    "\n",
    "ax.set_title('Risk-Return Profile: All Portfolios', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Annualized Volatility (%)')\n",
    "ax.set_ylabel('Annualized Return (%)')\n",
    "ax.legend(loc='lower right', fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(asset_correlation, annot=True, cmap='RdYlGn_r', center=0,\n",
    "            fmt='.2f', square=True, linewidths=0.5, ax=ax,\n",
    "            vmin=-1, vmax=1)\n",
    "\n",
    "ax.set_title('Asset Class Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Performance Metrics Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart comparing key metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "colors = [PORTFOLIOS[name]['color'] for name in metrics_df.index]\n",
    "\n",
    "# Annualized Return\n",
    "ax1 = axes[0, 0]\n",
    "metrics_df['Ann_Return_%'].plot(kind='bar', ax=ax1, color=colors)\n",
    "ax1.set_title('Annualized Return (%)', fontweight='bold')\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "ax1.axhline(y=metrics_df.loc['A_Baseline_60_40', 'Ann_Return_%'], color='black', linestyle='--', label='Baseline')\n",
    "\n",
    "# Sharpe Ratio\n",
    "ax2 = axes[0, 1]\n",
    "metrics_df['Sharpe_Ratio'].plot(kind='bar', ax=ax2, color=colors)\n",
    "ax2.set_title('Sharpe Ratio', fontweight='bold')\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "ax2.axhline(y=metrics_df.loc['A_Baseline_60_40', 'Sharpe_Ratio'], color='black', linestyle='--', label='Baseline')\n",
    "\n",
    "# Max Drawdown\n",
    "ax3 = axes[1, 0]\n",
    "metrics_df['Max_Drawdown_%'].plot(kind='bar', ax=ax3, color=colors)\n",
    "ax3.set_title('Maximum Drawdown (%)', fontweight='bold')\n",
    "ax3.set_xticklabels(ax3.get_xticklabels(), rotation=45, ha='right')\n",
    "ax3.axhline(y=metrics_df.loc['A_Baseline_60_40', 'Max_Drawdown_%'], color='black', linestyle='--', label='Baseline')\n",
    "\n",
    "# Volatility\n",
    "ax4 = axes[1, 1]\n",
    "metrics_df['Ann_Volatility_%'].plot(kind='bar', ax=ax4, color=colors)\n",
    "ax4.set_title('Annualized Volatility (%)', fontweight='bold')\n",
    "ax4.set_xticklabels(ax4.get_xticklabels(), rotation=45, ha='right')\n",
    "ax4.axhline(y=metrics_df.loc['A_Baseline_60_40', 'Ann_Volatility_%'], color='black', linestyle='--', label='Baseline')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Statistical Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Paired T-Test for Return Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_return_improvement(portfolio_returns, baseline_col='A_Baseline_60_40'):\n",
    "    \"\"\"\n",
    "    Perform paired t-test to check if portfolios significantly outperform baseline.\n",
    "    \"\"\"\n",
    "    baseline = portfolio_returns[baseline_col]\n",
    "    results = []\n",
    "    \n",
    "    for col in portfolio_returns.columns:\n",
    "        if col == baseline_col:\n",
    "            continue\n",
    "            \n",
    "        portfolio = portfolio_returns[col]\n",
    "        \n",
    "        # Paired t-test\n",
    "        t_stat, p_value = stats.ttest_rel(portfolio, baseline)\n",
    "        \n",
    "        # Calculate mean difference\n",
    "        mean_diff = (portfolio - baseline).mean() * 12 * 100  # Annualized %\n",
    "        \n",
    "        results.append({\n",
    "            'Portfolio': col,\n",
    "            'Mean_Diff_%': mean_diff,\n",
    "            't_statistic': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'Significant_5%': 'Yes' if p_value < 0.05 else 'No',\n",
    "            'Significant_10%': 'Yes' if p_value < 0.10 else 'No',\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run t-tests\n",
    "ttest_results = test_return_improvement(portfolio_returns)\n",
    "print(\"Paired T-Test Results (vs 60/40 Baseline):\\n\")\n",
    "print(ttest_results.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Bootstrap Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sharpe_ratio(returns, rf_returns, n_bootstrap=5000, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculate bootstrap confidence interval for Sharpe ratio.\n",
    "    \"\"\"\n",
    "    n = len(returns)\n",
    "    sharpe_ratios = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        # Sample with replacement\n",
    "        idx = np.random.choice(n, size=n, replace=True)\n",
    "        sample_returns = returns.iloc[idx]\n",
    "        sample_rf = rf_returns.iloc[idx]\n",
    "        \n",
    "        # Calculate Sharpe ratio\n",
    "        sr = sharpe_ratio(sample_returns, sample_rf)\n",
    "        sharpe_ratios.append(sr)\n",
    "    \n",
    "    sharpe_ratios = np.array(sharpe_ratios)\n",
    "    \n",
    "    # Calculate confidence interval\n",
    "    alpha = 1 - confidence\n",
    "    lower = np.percentile(sharpe_ratios, alpha/2 * 100)\n",
    "    upper = np.percentile(sharpe_ratios, (1 - alpha/2) * 100)\n",
    "    \n",
    "    return {\n",
    "        'mean': np.mean(sharpe_ratios),\n",
    "        'std': np.std(sharpe_ratios),\n",
    "        'lower_95': lower,\n",
    "        'upper_95': upper,\n",
    "    }\n",
    "\n",
    "# Calculate bootstrap CIs for key portfolios\n",
    "print(\"Bootstrap 95% Confidence Intervals for Sharpe Ratio:\\n\")\n",
    "print(f\"{'Portfolio':<25} {'Sharpe':<10} {'95% CI':<20}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for col in ['A_Baseline_60_40', 'B_Plus_Infra', 'E_Infra_Credit', 'F_All_Three']:\n",
    "    returns = portfolio_returns[col]\n",
    "    rf = rf_returns.reindex(returns.index).fillna(0)\n",
    "    \n",
    "    bootstrap_result = bootstrap_sharpe_ratio(returns, rf, n_bootstrap=5000)\n",
    "    \n",
    "    print(f\"{col:<25} {bootstrap_result['mean']:.3f}      [{bootstrap_result['lower_95']:.3f}, {bootstrap_result['upper_95']:.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Sub-Period Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Define Analysis Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sub-periods\n",
    "PERIODS = {\n",
    "    'Full_Sample': (portfolio_returns.index[0], portfolio_returns.index[-1]),\n",
    "    'GFC_Crisis': ('2008-01-01', '2009-12-31'),\n",
    "    'QE_Era': ('2013-01-01', '2019-12-31'),\n",
    "    'COVID_2020': ('2020-01-01', '2020-12-31'),\n",
    "    'Inflation_2021_2023': ('2021-01-01', '2023-12-31'),\n",
    "    'Year_2022': ('2022-01-01', '2022-12-31'),\n",
    "}\n",
    "\n",
    "def filter_to_period(returns_df, start_date, end_date):\n",
    "    \"\"\"Filter returns to specific period.\"\"\"\n",
    "    mask = (returns_df.index >= start_date) & (returns_df.index <= end_date)\n",
    "    return returns_df[mask]\n",
    "\n",
    "# Check data availability for each period\n",
    "print(\"Data Availability by Period:\\n\")\n",
    "for period_name, (start, end) in PERIODS.items():\n",
    "    filtered = filter_to_period(portfolio_returns, start, end)\n",
    "    if len(filtered) > 0:\n",
    "        print(f\"  {period_name:<25}: {len(filtered)} months ({filtered.index[0].strftime('%Y-%m')} to {filtered.index[-1].strftime('%Y-%m')})\")\n",
    "    else:\n",
    "        print(f\"  {period_name:<25}: No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Calculate Metrics by Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_period_metrics(portfolio_returns, rf_returns, periods_dict):\n",
    "    \"\"\"\n",
    "    Calculate key metrics for each period.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for period_name, (start, end) in periods_dict.items():\n",
    "        period_returns = filter_to_period(portfolio_returns, start, end)\n",
    "        period_rf = filter_to_period(rf_returns.to_frame(), start, end).iloc[:, 0]\n",
    "        \n",
    "        if len(period_returns) < 6:  # Need at least 6 months\n",
    "            continue\n",
    "        \n",
    "        for col in period_returns.columns:\n",
    "            returns = period_returns[col]\n",
    "            rf = period_rf.reindex(returns.index).fillna(0)\n",
    "            \n",
    "            # Calculate cumulative return for the period\n",
    "            cum_return = (1 + returns).prod() - 1\n",
    "            \n",
    "            all_results.append({\n",
    "                'Period': period_name,\n",
    "                'Portfolio': col,\n",
    "                'Months': len(returns),\n",
    "                'Cumulative_%': cum_return * 100,\n",
    "                'Ann_Return_%': annualized_return(returns) * 100 if len(returns) >= 12 else cum_return * 100,\n",
    "                'Volatility_%': annualized_volatility(returns) * 100,\n",
    "                'Sharpe': sharpe_ratio(returns, rf),\n",
    "                'Max_DD_%': max_drawdown(returns) * 100,\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# Calculate\n",
    "period_metrics = calculate_period_metrics(portfolio_returns, rf_returns, PERIODS)\n",
    "\n",
    "# Display 2022 specifically (critical stress test)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CRITICAL: 2022 STRESS TEST RESULTS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "year_2022 = period_metrics[period_metrics['Period'] == 'Year_2022'].copy()\n",
    "if len(year_2022) > 0:\n",
    "    year_2022 = year_2022.set_index('Portfolio')[['Cumulative_%', 'Volatility_%', 'Max_DD_%']]\n",
    "    year_2022 = year_2022.sort_values('Cumulative_%', ascending=False)\n",
    "    print(year_2022.round(2))\n",
    "else:\n",
    "    print(\"2022 data not available in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Period Comparison Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table for cumulative returns by period\n",
    "if len(period_metrics) > 0:\n",
    "    pivot_returns = period_metrics.pivot(index='Portfolio', columns='Period', values='Cumulative_%')\n",
    "    \n",
    "    # Reorder columns\n",
    "    col_order = [c for c in PERIODS.keys() if c in pivot_returns.columns]\n",
    "    pivot_returns = pivot_returns[col_order]\n",
    "    \n",
    "    # Plot heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    sns.heatmap(pivot_returns, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "                linewidths=0.5, ax=ax)\n",
    "    \n",
    "    ax.set_title('Cumulative Returns (%) by Period and Portfolio', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Period')\n",
    "    ax.set_ylabel('Portfolio')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Insufficient data for period analysis heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Results Summary & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary\n",
    "print(\"=\"*70)\n",
    "print(\"BACKTESTING RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAnalysis Period: {analysis_returns.index[0].strftime('%Y-%m')} to {analysis_returns.index[-1].strftime('%Y-%m')}\")\n",
    "print(f\"Total Months: {len(analysis_returns)}\")\n",
    "print()\n",
    "\n",
    "# Rank portfolios by Sharpe ratio\n",
    "ranking = metrics_df[['Ann_Return_%', 'Ann_Volatility_%', 'Sharpe_Ratio', 'Max_Drawdown_%']].copy()\n",
    "ranking['Rank'] = ranking['Sharpe_Ratio'].rank(ascending=False).astype(int)\n",
    "ranking = ranking.sort_values('Rank')\n",
    "\n",
    "print(\"PORTFOLIO RANKINGS (by Sharpe Ratio):\\n\")\n",
    "print(ranking.round(2))\n",
    "\n",
    "# Improvement summary\n",
    "baseline_sharpe = metrics_df.loc['A_Baseline_60_40', 'Sharpe_Ratio']\n",
    "baseline_return = metrics_df.loc['A_Baseline_60_40', 'Ann_Return_%']\n",
    "baseline_dd = metrics_df.loc['A_Baseline_60_40', 'Max_Drawdown_%']\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"IMPROVEMENT VS 60/40 BASELINE:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"\\nBaseline 60/40: Return={baseline_return:.2f}%, Sharpe={baseline_sharpe:.2f}, MaxDD={baseline_dd:.2f}%\\n\")\n",
    "\n",
    "for col in ['B_Plus_Infra', 'E_Infra_Credit', 'F_All_Three', 'G_Aggressive']:\n",
    "    ret_diff = metrics_df.loc[col, 'Ann_Return_%'] - baseline_return\n",
    "    sharpe_diff = metrics_df.loc[col, 'Sharpe_Ratio'] - baseline_sharpe\n",
    "    dd_diff = metrics_df.loc[col, 'Max_Drawdown_%'] - baseline_dd\n",
    "    \n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Return: {'+' if ret_diff > 0 else ''}{ret_diff:.2f}%\")\n",
    "    print(f\"  Sharpe: {'+' if sharpe_diff > 0 else ''}{sharpe_diff:.3f}\")\n",
    "    print(f\"  MaxDD:  {'+' if dd_diff > 0 else ''}{dd_diff:.2f}% {'(worse)' if dd_diff < 0 else '(better)'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best portfolio\n",
    "best_sharpe_portfolio = metrics_df['Sharpe_Ratio'].idxmax()\n",
    "best_return_portfolio = metrics_df['Ann_Return_%'].idxmax()\n",
    "best_dd_portfolio = metrics_df['Max_Drawdown_%'].idxmax()  # Least negative\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "1. BEST RISK-ADJUSTED RETURNS (Sharpe Ratio):\n",
    "   → {best_sharpe_portfolio}\n",
    "   → Sharpe: {metrics_df.loc[best_sharpe_portfolio, 'Sharpe_Ratio']:.3f}\n",
    "\n",
    "2. HIGHEST ABSOLUTE RETURNS:\n",
    "   → {best_return_portfolio}\n",
    "   → Return: {metrics_df.loc[best_return_portfolio, 'Ann_Return_%']:.2f}%\n",
    "\n",
    "3. LOWEST DRAWDOWN:\n",
    "   → {best_dd_portfolio}\n",
    "   → Max DD: {metrics_df.loc[best_dd_portfolio, 'Max_Drawdown_%']:.2f}%\n",
    "\n",
    "4. INFRASTRUCTURE IMPACT (Portfolio B vs A):\n",
    "   → Return improvement: {metrics_df.loc['B_Plus_Infra', 'Ann_Return_%'] - baseline_return:.2f}%\n",
    "   → Sharpe improvement: {metrics_df.loc['B_Plus_Infra', 'Sharpe_Ratio'] - baseline_sharpe:.3f}\n",
    "\n",
    "5. DIVERSIFICATION BENEFIT:\n",
    "   → Infrastructure correlation to Equity: {asset_correlation.loc['Infrastructure', 'Equity']:.2f}\n",
    "   → Infrastructure correlation to Bonds: {asset_correlation.loc['Infrastructure', 'Bonds']:.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Limitations & Caveats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "================================================================================\n",
    "IMPORTANT LIMITATIONS & CAVEATS\n",
    "================================================================================\n",
    "\n",
    "1. PROXY LIMITATIONS:\n",
    "   • Infrastructure (IGF): Listed infrastructure ETF, NOT private infrastructure\n",
    "     - Higher volatility than true private infrastructure\n",
    "     - Higher correlation to equity markets\n",
    "   \n",
    "   • Private Credit (HYG): High-yield bonds, NOT direct lending\n",
    "     - Fixed rate (not floating like true private credit)\n",
    "     - Different risk/return profile\n",
    "   \n",
    "   • Real Assets (GNR): Natural resource EQUITIES, NOT actual farmland/timberland\n",
    "     - Much higher volatility than NCREIF indices\n",
    "     - Higher correlation to equity markets\n",
    "\n",
    "2. DATA LIMITATIONS:\n",
    "   • ETF history limited (most start 2007-2011)\n",
    "   • May not capture full GFC drawdown\n",
    "   • Results may differ with institutional-quality indices\n",
    "\n",
    "3. IMPLEMENTATION REALITY:\n",
    "   • True private assets have:\n",
    "     - 10-15 year lockups (vs. daily liquidity for ETFs)\n",
    "     - Higher fees (2-4% vs. 0.3-0.5% for ETFs)\n",
    "     - J-curve effects in early years\n",
    "   • Backtest assumes instant rebalancing (not realistic for illiquid assets)\n",
    "\n",
    "4. STATISTICAL CAVEATS:\n",
    "   • Limited sample size for some periods\n",
    "   • Past performance does not guarantee future results\n",
    "   • Regime changes may alter correlations and returns\n",
    "\n",
    "RECOMMENDATION:\n",
    "   • Use these results as DIRECTIONAL GUIDANCE\n",
    "   • Validate with institutional-quality data if available (NCREIF, EDHECinfra)\n",
    "   • Apply conservative adjustments to ETF proxy results\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "import os\n",
    "os.makedirs('./output', exist_ok=True)\n",
    "\n",
    "# Export data\n",
    "monthly_returns.to_csv('./output/monthly_returns_all_assets.csv')\n",
    "portfolio_returns.to_csv('./output/portfolio_returns.csv')\n",
    "metrics_df.to_csv('./output/performance_metrics.csv')\n",
    "asset_correlation.to_csv('./output/correlation_matrix.csv')\n",
    "quality_summary.to_csv('./output/data_quality_summary.csv')\n",
    "\n",
    "if len(period_metrics) > 0:\n",
    "    period_metrics.to_csv('./output/period_metrics.csv', index=False)\n",
    "\n",
    "print(\"Results exported to ./output/ directory:\")\n",
    "print(\"  • monthly_returns_all_assets.csv\")\n",
    "print(\"  • portfolio_returns.csv\")\n",
    "print(\"  • performance_metrics.csv\")\n",
    "print(\"  • correlation_matrix.csv\")\n",
    "print(\"  • data_quality_summary.csv\")\n",
    "print(\"  • period_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "1. **Validate with Better Data:**\n",
    "   - Obtain NCREIF Timberland/Farmland indices\n",
    "   - Obtain Cliffwater Direct Lending Index\n",
    "   - Obtain EDHECinfra for unlisted infrastructure\n",
    "\n",
    "2. **Sensitivity Analysis:**\n",
    "   - Test different weight combinations\n",
    "   - Apply volatility adjustments to proxies\n",
    "   - Test different rebalancing frequencies\n",
    "\n",
    "3. **Present Findings:**\n",
    "   - Prepare board presentation\n",
    "   - Document methodology and limitations\n",
    "   - Recommend implementation approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
